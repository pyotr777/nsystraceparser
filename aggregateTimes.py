#!/usr/bin/env python3

# Aggregate time of individual operations and NVTX areas from JSON files generated by runTraceSeries.

import os
import argparse
import pandas as pd
import numpy as np
import subprocess
import matplotlib
from matplotlib import pyplot as plt
from matplotlib.ticker import MultipleLocator
from matplotlib import cm
import string
import re
import glob

ver = '1.04a'
description = 'Aggrgating trace events and NVTX data from SQlite files, saving it to a CSV files.'
print('{} v.{}'.format(description, ver))


# Get int number from a string of format ['nvtx region name ' 'iteration N']
# Returns iteration number as int and nvtx region name as string
def parseIteration(r):
    if len(r) == 0:
        return np.nan, np.nan, np.nan
    r = r['nvtx']
    nvtx_org = r
    if r == '':
        return np.nan, '', nvtx_org
    r = r.split('\' \'')
    i = np.nan
    nvtx = ''
    for s in r:
        s = s.strip('[]\'')
        if 'iteration' in s.lower():
            i = int(s.strip(string.ascii_letters).strip(' ,'))
        else:
            nvtx = s
    return i, nvtx, nvtx_org


def main():
    parser = argparse.ArgumentParser(description=description)
    parser.add_argument("--dir", '-d', default=None, required=True,
                        help="Directory with nsys traces to parse.")
    parser.add_argument('--nvtx-filters', nargs='*', default=None,
                        help="Pattern for searching NVTX regions")
    parser.add_argument('--event-filters', nargs='*', default=None,
                        help="Patterns for searching events regions.")
    parser.add_argument('--debug', action='store_true')
    parser.add_argument(
        '--convert-traces', action='store_true', default=False,
        help="Call parseOneTrace.py overwriting existing events.csv and nvtx.csv files")

    args = parser.parse_args()

    files_paths = glob.glob(os.path.join(args.dir, '*.sqlite'))
    trace_name_pattern = re.compile(r"^nsys_trace_([0-9]+)\.sqlite$")
    files = []
    param_values = []
    for fullname in files_paths:
        filename = os.path.basename(fullname)
        print(filename, fullname)
        m = re.match(trace_name_pattern, filename)
        if m:
            files.append(os.path.abspath(os.path.join(args.dir, filename)))
            param_values.append(m.group(1))

    # Mark: parse traces
    eventsDF = None
    nvtxDF = None
    for param, tracefile in zip(param_values, files):
        if args.convert_traces:
            # Run
            # python3 parseOneTrace.py -f $tracefile --events $events
            command = 'python3@parseOneTrace.py@-f@{}'.format(tracefile)
            # if args.nvtx_filters is not None:
            #     nvtxs = '@'.join(args.nvtx_filters)
            #     command += '@--nvtx-filters@{}'.format(nvtxs)
            # if args.event_filters is not None:
            #     events = '@'.join(args.event_filters)
            #     print("Events: {}".format(events))
            #     command += '@--event-filters@{}'.format(events)
            print(command.split('@'))
            p = subprocess.run(command.split('@'), stdout=subprocess.PIPE,
                               stderr=subprocess.PIPE, bufsize=0, shell=False)
            if p.returncode == 0:
                print(p.stdout.decode('utf-8'))
                print('Finished OK')
            else:
                if p.stdout is not None:
                    print(p.stdout.decode('utf-8'))
                print('ERROR')
                print(p.stderr.decode('utf-8'))
        # Read data from CSV file
        directory = os.path.dirname(tracefile)
        csvfilebase = ('').join(
            os.path.basename(tracefile).split('.')[:-1])  # Filename without extension
        print('Reading {}'.format(csvfilebase))
        # Read to CSV files
        events_csvfile = csvfilebase + '_evnt.csv'
        events_csvfile = os.path.join(directory, events_csvfile)
        events_ = pd.read_csv(events_csvfile)
        events_.loc[:, 'param'] = param
        nvtx_csvfile = csvfilebase + '_nvtx.csv'
        nvtx_csvfile = os.path.join(directory, nvtx_csvfile)
        nvtx_ = pd.read_csv(nvtx_csvfile)
        nvtx_.loc[:, 'param'] = param

        if eventsDF is None:
            eventsDF = events_
        else:
            eventsDF = pd.concat([eventsDF, events_], ignore_index=True)
        if nvtxDF is None:
            nvtxDF = nvtx_
        else:
            nvtxDF = pd.concat([nvtxDF, nvtx_], ignore_index=True)

    eventsDF['nvtx'] = eventsDF['nvtx'].fillna('')
    eventsDF.loc[:, 'iteration'] = np.nan
    results = eventsDF.apply(parseIteration, axis=1, result_type='expand')
    eventsDF.loc[:, ['iteration', 'nvtx', 'nvtx_org']] = results.values
    for col in ['param', 'correlationId', 'iteration']:
        eventsDF[col] = eventsDF[col].astype("Int16", errors='ignore')
    # Calculate GPU time
    eventsDF.loc[:, 'duration_gpu'] = eventsDF['end_gpu'] - eventsDF['start_gpu']
    eventsDF.loc[:, 'duration'] = eventsDF['end'] - eventsDF['start']
    eventsDF = eventsDF.replace('[]', np.nan)

    # Mark: save CSV files
    eventsdf_file = "events.csv"
    nvtxdf_file = "nvtx.csv"
    eventsDF.to_csv(os.path.join(args.dir, eventsdf_file), index=False)
    nvtxDF.to_csv(os.path.join(args.dir, nvtxdf_file), index=False)
    print("Saved events to", os.path.join(args.dir, eventsdf_file))
    print("Saved nvtx to", os.path.join(args.dir, nvtxdf_file))

    # Plot times of each kernel type
    times = eventsDF.copy()
    times = times[times['start_gpu'].notna()]
    # Drop first and last iterations
    times['iteration'] = times['iteration'].astype(int)
    iterations = sorted(times['iteration'].unique())
    iterations = iterations[1:-1]
    times = times[times['iteration'].isin(iterations)]

    times.loc[:, 'name'] = times.apply(
        lambda r: '{} {}'.format(r.loc['shortName'], r.loc['nvtx']), axis=1)
    usecolumns = ['duration', 'duration_gpu', 'name', 'param', 'iteration']
    times = times[usecolumns]
    times = times.groupby(['param', 'name',
                           'iteration']).agg('sum').reset_index(drop=False)
    times = times.groupby(['param', 'name']).agg('mean').reset_index(drop=False)
    times.drop(['iteration'], axis=1, inplace=True)

    # GPU time
    df_ = times.pivot(index=['name'], values='duration_gpu', columns=['param']).fillna(0)
    df_.loc[:, 'total'] = df_.sum(axis=1)
    df_ = df_.sort_values(['total'], ascending=False)
    df_ = df_.drop(['total'], axis=1)
    N = df_.shape[0] - 30
    fig, ax = plt.subplots(figsize=(10, 5), dpi=144)
    col3 = getColorList('viridis', n=N)
    col1 = getColorList('tab10', n=10)
    col2 = getColorList('tab20', n=20)
    colors = col2 + col1 + col3
    N = len(colors)
    cmap = matplotlib.colors.LinearSegmentedColormap.from_list("combined", colors, N=N)
    df_.T.plot.area(cmap=cmap, ax=ax)
    ax.set_xlim(0, None)
    ax.minorticks_on()
    ax.xaxis.set_major_locator(MultipleLocator(10))
    ax.xaxis.set_minor_locator(MultipleLocator(5))
    ax.grid(ls=':', lw=0.7)
    ax.grid(ls=':', lw=0.3, which='minor')
    ax.set_title("Events GPU time per iteration for {}".format(args.dir))
    ax.text(0,-0.1,"No first and last iterations.\n"\
            "Time aggregated as sums of times of events of the same type in each iteration,\n"\
            "mean across iterations.",va='top',ha='left',
                                                 transform=ax.transAxes)
    handles, labels = ax.get_legend_handles_labels()
    ax.legend(handles[::-1], labels[::-1], frameon=False, ncol=2, loc='upper left',
              bbox_to_anchor=(1, 1))
    path = os.path.join(args.dir, "cuda_kernel_times.pdf")
    plt.savefig(path, bbox_inches='tight')
    plt.close()
    print(f"Saved {path}")

    # Plot GPU time of filtered events
    df_ = times.copy()
    dfT = None
    if args.event_filters is not None:
        for substr in args.event_filters:
            dfs = df_[df_['name'].str.lower().str.contains(substr.lower())]
            ab = df_.shape[0]
            a = dfs.shape[0]
            df_ = df_[~df_['name'].str.lower().str.contains(substr.lower())]
            b = df_.shape[0]
            assert ab == a + b, f"DF shape do not add up: {a} + {b} != {df_.shape[0]}(!={AB})"
            dfs = dfs[['param', 'duration_gpu'
                       ]].groupby(['param'
                                   ]).agg('sum').rename(columns={"duration_gpu": substr})
            if dfT is None:
                dfT = dfs
            else:
                dfT = pd.concat([dfT, dfs], axis=1)

        fig, ax = plt.subplots(figsize=(10, 5), dpi=144)
        dfT.plot.area(ax=ax)
        ax.set_xlim(0, None)
        ax.minorticks_on()
        ax.xaxis.set_major_locator(MultipleLocator(10))
        ax.xaxis.set_minor_locator(MultipleLocator(5))
        ax.grid(ls=':', lw=0.7)
        ax.grid(ls=':', lw=0.3, which='minor')
        ax.set_title("Filtered events GPU time per iteration for {}".format(args.dir))
        handles, labels = ax.get_legend_handles_labels()
        ax.legend(handles[::-1], labels[::-1], frameon=False, loc='upper left',
                  bbox_to_anchor=(1, 1), edgecolor='white')
        path = os.path.join(args.dir, "cuda_kernel_times_filtered.pdf")
        plt.savefig(path, bbox_inches='tight')
        plt.close()
        print(f"Saved {path}")
        path = os.path.join(args.dir, "cuda_kernel_times_filtered.csv")
        dfT.to_csv(path)
        print(f"Saved {path}")

    # Plot GPU times of NVTX ranges (containing substrings from nvtx_filters)
    dfT = pd.DataFrame()
    if args.nvtx_filters is not None:
        for substr in args.nvtx_filters:
            dfs = eventsDF[eventsDF['nvtx'].str.lower().str.contains(
                substr.lower())].copy()
            dfs = dfs[['param', 'iteration', 'shortName', 'duration_gpu']]
            dfs = dfs.groupby(['param', 'iteration', 'shortName'],
                              as_index=False).agg('sum')
            dfs['shortName'] = substr + ' ' + dfs['shortName']
            dfT_ = dfs.pivot_table(index='param', columns='shortName',
                                   values='duration_gpu', aggfunc='mean')
            dfT = pd.concat([dfT, dfT_], axis=1)

        fig, ax = plt.subplots(figsize=(10, 5), dpi=144)
        dfT.plot.area(ax=ax)
        ax.set_xlim(0, None)
        ax.minorticks_on()
        ax.xaxis.set_major_locator(MultipleLocator(10))
        ax.xaxis.set_minor_locator(MultipleLocator(5))
        ax.grid(ls=':', lw=0.7)
        ax.grid(ls=':', lw=0.3, which='minor')
        ax.set_title("GPU time per iteration of NVTX ranges for {}".format(args.dir))
        handles, labels = ax.get_legend_handles_labels()
        ax.legend(handles[::-1], labels[::-1], frameon=False, loc='upper left',
                  bbox_to_anchor=(1, 1), edgecolor='white')
        path = os.path.join(args.dir, "nvtx_gpu_times_filtered.pdf")
        plt.savefig(path, bbox_inches='tight')
        plt.close()
        print(f"Saved {path}")
        path = os.path.join(args.dir, "nvtx_gpu_times_filtered.csv")
        dfT.to_csv(path)
        print(f"Saved {path}")

    print("All done.")


def getColorList(cmap, n=16):
    cmap = cm.get_cmap(cmap, n)
    colors = []
    for i in range(cmap.N):
        c = matplotlib.colors.to_hex(cmap(i), keep_alpha=True)
        colors.append(c)
    return colors


if __name__ == '__main__':
    main()